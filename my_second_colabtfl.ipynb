{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_second_colabtfl.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/scarimp/TFL_COLAB/blob/master/my_second_colabtfl.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "bSXpVM1hCz38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "994e21d6-131d-4fc2-d84e-f073c757b589"
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already up-to-date: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
            "Requirement already up-to-date: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
            "Requirement already up-to-date: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
            "Requirement already up-to-date: tensorboard<1.8.0,>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
            "Requirement already up-to-date: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
            "Requirement already up-to-date: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
            "Requirement already up-to-date: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
            "Requirement already up-to-date: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
            "Requirement already up-to-date: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
            "Requirement already up-to-date: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
            "Requirement already up-to-date: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
            "Requirement already up-to-date: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
            "Requirement already up-to-date: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
            "Requirement already up-to-date: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7hIifCVIjH1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6e48659a-ca29-4b40-a6f1-18aaf563dc30"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: {}\".format(tf.VERSION))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HWLHCG9QDLNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "620c15f3-449d-4f96-c8bf-30ce786cab76"
      },
      "cell_type": "code",
      "source": [
        "!pip install tflearn\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.6/dist-packages\r\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn)\r\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn)\r\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YEAiMpr7haq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "0dc49de7-486e-47fc-eafd-482ceb839954"
      },
      "cell_type": "code",
      "source": [
        "!pip install dlib"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dlib\n",
            "  Using cached https://files.pythonhosted.org/packages/54/ff/5781a11bdc0d1c90a813f3f66d460abf628e5114856a842d18d43f709a7a/dlib-19.10.0.tar.gz\n",
            "Building wheels for collected packages: dlib\n",
            "  Running setup.py bdist_wheel for dlib ... \u001b[?25l-\b \berror\n",
            "  Complete output from command /usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-xr78u8k4/dlib/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/tmp7nssc1h9pip-wheel- --python-tag cp36:\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  package init file 'dlib/__init__.py' not found (or not a regular file)\n",
            "  running build_ext\n",
            "  Invoking CMake setup: 'cmake /tmp/pip-build-xr78u8k4/dlib/tools/python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=/tmp/pip-build-xr78u8k4/dlib/build/lib.linux-x86_64-3.6 -DPYTHON_EXECUTABLE=/usr/bin/python3 -DCMAKE_BUILD_TYPE=Release'\n",
            "  error: [Errno 2] No such file or directory: 'cmake': 'cmake'\n",
            "  \n",
            "  ----------------------------------------\n",
            "\u001b[31m  Failed building wheel for dlib\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for dlib\n",
            "Failed to build dlib\n",
            "Installing collected packages: dlib\n",
            "  Running setup.py install for dlib ... \u001b[?25l-\b \berror\n",
            "    Complete output from command /usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-xr78u8k4/dlib/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-882gcxc9-record/install-record.txt --single-version-externally-managed --compile:\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    package init file 'dlib/__init__.py' not found (or not a regular file)\n",
            "    running build_ext\n",
            "    Invoking CMake setup: 'cmake /tmp/pip-build-xr78u8k4/dlib/tools/python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=/tmp/pip-build-xr78u8k4/dlib/build/lib.linux-x86_64-3.6 -DPYTHON_EXECUTABLE=/usr/bin/python3 -DCMAKE_BUILD_TYPE=Release'\n",
            "    error: [Errno 2] No such file or directory: 'cmake': 'cmake'\n",
            "    \n",
            "    ----------------------------------------\n",
            "\u001b[31mCommand \"/usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-xr78u8k4/dlib/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-882gcxc9-record/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-build-xr78u8k4/dlib/\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ouc4sa6PFn5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "437484c2-ce72-4275-e5f5-996a61852920"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tflearn\n",
        "\n",
        "import tflearn.datasets.mnist as mnist"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the retry module or similar alternatives.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cpy78nzUGmS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "79de95c8-c900-4a46-d7c9-24cbbe8a8ab9"
      },
      "cell_type": "code",
      "source": [
        "X, Y, testX, testY = mnist.load_data(one_hot=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/train-images-idx3-ubyte.gz\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ple3chN7G2_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "e91869b5-dda8-4bcf-8dbe-0ea545b3e793"
      },
      "cell_type": "code",
      "source": [
        "print(X[:10], Y[:20])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z6Z770QjKFn6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "UhIvA2RxJpQU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The **softmax function at ** :https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/\n"
      ]
    },
    {
      "metadata": {
        "id": "TQulJyLyFiBq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import tflearn\n",
        "import tflearn.datasets.mnist as mnist\n",
        "\n",
        "# MNIST Data\n",
        "X, Y, testX, testY = mnist.load_data(one_hot=True)\n",
        "\n",
        "# Model\n",
        "input_layer = tflearn.input_data(shape=[None, 784], name='input')\n",
        "dense1 = tflearn.fully_connected(input_layer, 128, name='dense1')\n",
        "dense2 = tflearn.fully_connected(dense1, 256, name='dense2')\n",
        "#\n",
        "softmax = tflearn.fully_connected(dense2, 10, activation='softmax')\n",
        "regression = tflearn.regression(softmax, optimizer='adam',\n",
        "                                learning_rate=0.001,\n",
        "                                loss='categorical_crossentropy')\n",
        "\n",
        "# Define classifier, with model checkpoint (autosave)\n",
        "model = tflearn.DNN(regression, checkpoint_path='model.tfl.ckpt')\n",
        "\n",
        "# Train model, with model checkpoint every epoch and every 200 training steps.\n",
        "model.fit(X, Y, n_epoch=1,\n",
        "          validation_set=(testX, testY),\n",
        "          show_metric=True,\n",
        "          snapshot_epoch=True, # Snapshot (save & evaluate) model every epoch.\n",
        "          snapshot_step=500, # Snapshot (save & evalaute) model every 500 steps.\n",
        "          run_id='model_and_weights')\n",
        "\n",
        "\n",
        "# ---------------------\n",
        "# Save and load a model\n",
        "# ---------------------\n",
        "\n",
        "# Manually save model\n",
        "model.save(\"model.tfl\")\n",
        "\n",
        "# Load a model\n",
        "model.load(\"model.tfl\")\n",
        "\n",
        "# Or Load a model from auto-generated checkpoint\n",
        "# >> model.load(\"model.tfl.ckpt-500\")\n",
        "\n",
        "# Resume training\n",
        "model.fit(X, Y, n_epoch=1,\n",
        "          validation_set=(testX, testY),\n",
        "          show_metric=True,\n",
        "          snapshot_epoch=True,\n",
        "          run_id='model_and_weights')\n",
        "\n",
        "\n",
        "# ------------------\n",
        "# Retrieving weights\n",
        "# ------------------\n",
        "\n",
        "# Retrieve a layer weights, by layer name:\n",
        "dense1_vars = tflearn.variables.get_layer_variables_by_name('dense1')\n",
        "# Get a variable's value, using model `get_weights` method:\n",
        "print(\"Dense1 layer weights:\")\n",
        "print(model.get_weights(dense1_vars[0]))\n",
        "# Or using generic tflearn function:\n",
        "print(\"Dense1 layer biases:\")\n",
        "with model.session.as_default():\n",
        "    print(tflearn.variables.get_value(dense1_vars[1]))\n",
        "\n",
        "# It is also possible to retrieve a layer weights through its attributes `W`\n",
        "# and `b` (if available).\n",
        "# Get variable's value, using model `get_weights` method:\n",
        "print(\"Dense2 layer weights:\")\n",
        "print(model.get_weights(dense2.W))\n",
        "# Or using generic tflearn function:\n",
        "print(\"Dense2 layer biases:\")\n",
        "with model.session.as_default():\n",
        "print(tflearn.variables.get_value(dense2.b))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}