{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_toy_and_keras_random.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/scarimp/TFL_COLAB/blob/master/1_toy_and_keras_random.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "MOdo98n5CSiY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "810c465b-a7c5-4f67-f2d7-26c55f96da2e"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import keras \n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"keras vers.=\", keras.__version__)\n",
        "print(\"tensorflow vers.=\", tf.__version__)\n",
        "print(\"numpy vers.=\", np.__version__)\n",
        "print(\"matplotlib vers.=\", plt.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras vers.= 2.1.6\n",
            "tensorflow vers.= 1.9.0-rc2\n",
            "numpy vers.= 1.14.5\n",
            "matplotlib vers.= 2.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZQQJbMW---1h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A Pythonic Neuron  from [from Manning](https://www.manning.com/books/natural-language-processing-in-action/)"
      ]
    },
    {
      "metadata": {
        "id": "1RQGCgi6C43i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "20a3f60d-5f59-4f24-ca73-7d0643ca588c"
      },
      "cell_type": "code",
      "source": [
        "# a toy example of neural network \n",
        "# 5.1.4 A Pythonic Neuron \n",
        "example_input = [1, .2, .1, .05, .2]\n",
        "example_weights = [.2, .12, .4, .6, .90]\n",
        "input_vector = np.array(example_input) # Convert to numpy array so we can do pairwise math on the vectors easily\n",
        "weights = np.array(example_weights)\n",
        "bias_weight = .2\n",
        "activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
        "print(activation_level)\n",
        "threshold = 0.5\n",
        "if activation_level >= threshold:\n",
        "  perceptron_output = 1\n",
        "else:\n",
        "  perceptron_output = 0\n",
        "\n",
        "print(perceptron_output)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6740000000000002\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O7Wnn6b9C5iI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1049bf01-5d7e-4026-fede-3089f29a4534"
      },
      "cell_type": "code",
      "source": [
        "# Learn to recognize the boolean OR condition.\n",
        "sample_data = [[0, 0], # False, False\n",
        "              [0, 1], # False, True\n",
        "              [1, 0], # True, False\n",
        "              [1, 1]] # True, True\n",
        "expected_results = [0,\n",
        "                    1,\n",
        "                    1,\n",
        "                    1]\n",
        "activation_threshold = 0.5\n",
        "weights = np.random.random(2)/1000 # Small random float 0 < w < .001\n",
        "print(weights)\n",
        "\n",
        "bias_weight = np.random.random()/1000\n",
        "print(bias_weight)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.47108984e-04 1.63597389e-05]\n",
            "0.0007334976170058014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lk2e_FqODGmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "cf105947-f2a0-46a1-ec05-6fee8a18acc9"
      },
      "cell_type": "code",
      "source": [
        "for idx, sample in enumerate(sample_data):\n",
        "  input_vector = np.array(sample)\n",
        "  activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
        "  if activation_level > activation_threshold:\n",
        "    perceptron_output = 1\n",
        "  else:\n",
        "    perceptron_output = 0\n",
        "  print('Predicted {}'.format(perceptron_output))\n",
        "  print('Expected: {}'.format(expected_results[idx]))\n",
        "  print('============================')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted 0\n",
            "Expected: 0\n",
            "============================\n",
            "Predicted 0\n",
            "Expected: 1\n",
            "============================\n",
            "Predicted 0\n",
            "Expected: 1\n",
            "============================\n",
            "Predicted 0\n",
            "Expected: 1\n",
            "============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OMmv09J8EwbU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And finally instead of just printing 1 or 0, we will actually **update** the weights at each iteration."
      ]
    },
    {
      "metadata": {
        "id": "HcQmNlKrEbjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "367426d8-9f01-4054-8a75-3d7cb3ffb7ff"
      },
      "cell_type": "code",
      "source": [
        "for iteration_num in range(5):\n",
        "  correct_answers = 0\n",
        "  for idx, sample in enumerate(sample_data):\n",
        "    input_vector = np.array(sample)\n",
        "    weights = np.array(weights)\n",
        "    activation_level = np.dot(input_vector, weights) + (bias_weight * 1)\n",
        "    if activation_level > activation_threshold:\n",
        "      perceptron_output = 1\n",
        "    else:\n",
        "      perceptron_output = 0\n",
        "    if perceptron_output == expected_results[idx]:\n",
        "      correct_answers += 1\n",
        "      new_weights = []\n",
        "      for i, x in enumerate(sample):\n",
        "        \n",
        "        new_weights.append(weights[i] + (expected_results[idx] - perceptron_output) * x)\n",
        "        bias_weight = bias_weight + ((expected_results[idx] - perceptron_output) * 1)\n",
        "        \n",
        "      weights = np.array(new_weights)\n",
        "  print('{} correct answers out of 4, for iteration {}'.format(correct_answers, iteration_num))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 correct answers out of 4, for iteration 0\n",
            "1 correct answers out of 4, for iteration 1\n",
            "1 correct answers out of 4, for iteration 2\n",
            "1 correct answers out of 4, for iteration 3\n",
            "1 correct answers out of 4, for iteration 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ECJFBGukHP0l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But Minsky and Papert showed that if the data samples **weren’t linearly separable** into discrete groups the Perceptron would not be able\n",
        "to learn to ** classify**  the input data.\n",
        "\n",
        "BUT As most data in the world is not cleanly separable with lines and planes, Minsky and\n",
        "Paperts' \"proof\" relegated the Perceptron to the storage shelves. But the Perceptron idea\n",
        "didn’t die easily. It resurfaced again when Geoffrey Hinton and team footnoteref[3,\n",
        "Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986). Learning representations by\n",
        "back-propagating errors. Nature, 323, 533–536] showed you could use it **to solve the\n",
        "XOR problem** by using **multiple in Perceptrons** in concert. The key breakthrough was **a\n",
        "way to divide the error appropriately to each of the Perceptrons**. The way they did this\n",
        "was resurfacing an earlier concept called **backpropogation**. With this idea for\n",
        "backpropogation across neurons and then layers of neurons, *the first modern Neural\n",
        "Network was born*."
      ]
    },
    {
      "metadata": {
        "id": "s1mk3s_yHaRz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}